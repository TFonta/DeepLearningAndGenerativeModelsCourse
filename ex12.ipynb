{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f4101c-0ee4-4bc7-8c15-410a2fac5a7c",
   "metadata": {},
   "source": [
    "# Visualizing Training Statistics with Tensorboard\n",
    "PyTorch integrates with TensorBoard, a tool designed for visualizing the results of neural network training runs.\n",
    "\n",
    "In this tutorial, we’ll learn how to:\n",
    "\n",
    "- Set up TensorBoard.\n",
    "\n",
    "- Write to TensorBoard.\n",
    "\n",
    "- Inspect a model architecture using TensorBoard.\n",
    "\n",
    "- Use TensorBoard to create interactive versions of the statistics visualizations (like loss, accuracy, etc..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2055d69c-bfa4-4492-8eaa-9a936e5d5fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# transforms\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# datasets\n",
    "trainset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "# dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                        shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "# constant for classes\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    img = img.cpu()\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    \n",
    "    to_pil = transforms.ToPILImage()\n",
    "    \n",
    "    if one_channel:\n",
    "        npimg = img.numpy()\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(to_pil(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf4dc907-e72e-4ff7-ae93-235f51aac149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a18ba83-406d-4730-a830-dd7dd5df1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa26b0-1d7b-427b-82ea-5bd771ff592e",
   "metadata": {},
   "source": [
    "Now we’ll set up TensorBoard, importing tensorboard from <code>torch.utils</code> and defining a <code>SummaryWriter</code>, our key object for writing information to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4448f4c-13c0-4c51-b78d-d360a0dd6977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter #pip install tensorboard\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('./runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd04fa-907f-4bcb-9e71-90d61e32c812",
   "metadata": {},
   "source": [
    "Now let’s write an image to our TensorBoard - specifically, a grid using <code>make_grid</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60810f77-e4e0-4982-90da-1856914b28d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f256bd-14ee-40a6-b5c7-4a192e036d18",
   "metadata": {},
   "source": [
    "### Now lets run:\n",
    "<code>tensorboard --logdir=runs</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9bd9d6-cc1e-47ac-94cc-a98cd533615d",
   "metadata": {},
   "source": [
    "One of TensorBoard’s strengths is its ability to visualize complex model structures. Let’s visualize the model we built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b092e504-a3ca-48dd-ab9d-beee3d5151d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(net, images.to(device))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5374bbde-eb0c-438a-b87a-03fe944e3940",
   "metadata": {},
   "source": [
    "## Tracking Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f297e3-aca3-4328-836e-4c3dd93d4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Generates predictions and corresponding probabilities from a trained\n",
    "    network and a list of images\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Generates matplotlib Figure using a trained network, along with images\n",
    "    and labels from a batch, that shows the network's top prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(1, 4, idx+1, xticks=[], yticks=[])\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%\\n(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070cb570-837c-47af-bf6f-73a669f33392",
   "metadata": {},
   "source": [
    "Finally, let’s train the model using the usual model training code, but writing results to TensorBoard every 1000 batches instead of printing to console; this is done using the <code>add_scalar</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c9c5e29-17da-428c-9e5b-01e3c5f649d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# get gradients list for each layer in the network\n",
    "def add_gradient_hist(net):\n",
    "    ave_grads = [] \n",
    "    layers = []\n",
    "    for n,p in net.named_parameters():\n",
    "        if (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            if p.requires_grad: \n",
    "                ave_grad = np.abs(p.grad.clone().detach().cpu().numpy()).mean()\n",
    "            else:\n",
    "                ave_grad = 0\n",
    "            ave_grads.append(ave_grad)\n",
    "        \n",
    "    layers = [layers[i].replace(\".weight\", \"\") for i in range(len(layers))]\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    plt.bar(np.arange(len(ave_grads)), ave_grads, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads) + 1, lw=2, color=\"k\")\n",
    "    plt.xticks(range(0, len(ave_grads), 1), layers, rotation=90)\n",
    "    plt.xlim(left=0, right=len(ave_grads))\n",
    "    plt.ylim(bottom=-0.001, top=np.max(ave_grads) / 2)  # zoom in on the lower gradient regions\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    #plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['mean-gradient', 'zero-gradient'])\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "588636ba-7ac5-4b1e-b089-dae09e41444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 999 Loss: 1.797364261046052 Accuracy: 0.367\n",
      "It: 1999 Loss: 0.8388228156529367 Accuracy: 0.674\n",
      "It: 2999 Loss: 0.6794014632795006 Accuracy: 0.733\n",
      "It: 3999 Loss: 0.6169936868352816 Accuracy: 0.76825\n",
      "It: 4999 Loss: 0.5904314815660473 Accuracy: 0.7755\n",
      "It: 5999 Loss: 0.5336703596552834 Accuracy: 0.80175\n",
      "It: 6999 Loss: 0.5173798360140063 Accuracy: 0.8135\n",
      "It: 7999 Loss: 0.4872416841473896 Accuracy: 0.813\n",
      "It: 8999 Loss: 0.4552474887721473 Accuracy: 0.8295\n",
      "It: 9999 Loss: 0.4203879059451283 Accuracy: 0.846\n",
      "It: 10999 Loss: 0.43062954659987007 Accuracy: 0.84025\n",
      "It: 11999 Loss: 0.4143760200872785 Accuracy: 0.84425\n",
      "It: 12999 Loss: 0.39577380754461045 Accuracy: 0.8525\n",
      "It: 13999 Loss: 0.37163907055318124 Accuracy: 0.86325\n",
      "It: 14999 Loss: 0.3758912225854874 Accuracy: 0.855\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "running_loss = 0.0\n",
    "correct = 0.0\n",
    "\n",
    "# define a function to freeze the model layers\n",
    "def set_conv_parameter_requires_grad(model, req_grad = False):\n",
    "    for n,p in net.named_parameters():\n",
    "        if \"conv\" in n:\n",
    "            p.requires_grad = req_grad\n",
    "\n",
    "#set_conv_parameter_requires_grad(net)\n",
    "\n",
    "for epoch in range(1):  # loop over the dataset multiple times\n",
    "\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # put data to device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # ...log a Matplotlib Figure showing the model's gradients fo each layer\n",
    "        if i % 1000 == 999:\n",
    "            writer.add_figure('gradients',\n",
    "                            add_gradient_hist(net),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        correct += get_num_correct(outputs, labels)\n",
    "        if i % 1000 == 999:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "            writer.add_scalar('training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "            # ...log the training accuracy\n",
    "            writer.add_scalar('training accuracy',\n",
    "                            correct / (1000*inputs.size(0)), # inputs.size(0) is the batch size\n",
    "                            epoch * len(trainloader) + i)\n",
    "            \n",
    "            print('It: {} Loss: {} Accuracy: {}'.format(epoch * len(trainloader) + i, running_loss / 1000, correct / (1000*inputs.size(0))))\n",
    "\n",
    "            # ...log a Matplotlib Figure showing the model's predictions on a\n",
    "            # random mini-batch\n",
    "            writer.add_figure('predictions vs. actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            global_step=epoch * len(trainloader) + i)\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            correct = 0.0\n",
    "writer.close()\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42480d-f0e1-4de0-9cca-b4041dd38dbf",
   "metadata": {},
   "source": [
    "# Assessing trained models with TensorBoard\n",
    "Let's calculate the precision recall curve of our model.\n",
    "\n",
    "REMINDER:\n",
    "\n",
    "![alt text](https://miro.medium.com/max/720/0*eBNoU76LKUuCS6ap.png)\n",
    "\n",
    "Precision $P$ is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false positives ($F_p$). Precision can be thought of as the fraction of positive predictions that actually belong to the positive class:\n",
    "$$P = \\frac{T_p}{T_p + F_p}$$\n",
    "\n",
    "Recall $R$  is defined as the number of true positives ($T_p$) over the number of true positives plus the number of false negatives ($F_n$). Recall can be thought of as the fraction of positive predictions out of all positive instances in the data set:\n",
    "$$R = \\frac{T_p}{T_p + F_n}$$\n",
    "\n",
    "The precision-recall curve shows the tradeoff between precision and recall for different threshold. A high area under the curve represents both high recall and high precision, where high precision relates to a low false positive rate, and high recall relates to a low false negative rate. High scores for both show that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b14f457f-e642-49e2-beee-ebb26a0ea03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. gets the probability predictions in a test_size x num_classes Tensor\n",
    "# 2. gets the preds in a test_size Tensor\n",
    "# takes ~10 seconds to run\n",
    "class_probs = []\n",
    "class_label = []\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        output = net(images)\n",
    "        class_probs_batch = [F.softmax(el.cpu(), dim=0) for el in output]\n",
    "\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_label.append(labels.cpu())\n",
    "\n",
    "test_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "test_label = torch.cat(class_label)\n",
    "\n",
    "# helper function\n",
    "def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):\n",
    "    '''\n",
    "    Takes in a \"class_index\" from 0 to 9 and plots the corresponding\n",
    "    precision-recall curve\n",
    "    '''\n",
    "    tensorboard_truth = test_label == class_index\n",
    "    tensorboard_probs = test_probs[:, class_index]\n",
    "\n",
    "    writer.add_pr_curve(classes[class_index],\n",
    "                        tensorboard_truth,\n",
    "                        tensorboard_probs,\n",
    "                        global_step=global_step)\n",
    "    writer.close()\n",
    "\n",
    "# plot all the pr curves\n",
    "for i in range(len(classes)):\n",
    "    add_pr_curve_tensorboard(i, test_probs, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2792a2-b39f-4a09-b7bb-6e47547fcf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ex1: add plots for testing accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
